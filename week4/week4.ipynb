{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-29T13:57:42.439912Z",
          "start_time": "2025-07-29T13:57:39.803780Z"
        },
        "id": "c99271a972aa755"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import random\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque"
      ],
      "id": "c99271a972aa755",
      "outputs": [],
      "execution_count": 21
    },
    {
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-07-29T13:57:44.149490Z",
          "start_time": "2025-07-29T13:57:44.133703Z"
        },
        "id": "initial_id"
      },
      "cell_type": "code",
      "source": [
        "class Ball(object):\n",
        "    def __init__(self, x: int | float, y: int | float,\n",
        "                 spdx: int | float = 1, spdy: int | float = 1,\n",
        "                 radius: int | float = 10):\n",
        "        self.x, self.y = x, y\n",
        "        self.spdx, self.spdy = spdx, spdy\n",
        "        self.r = radius\n",
        "\n",
        "\n",
        "class Paddle(object):\n",
        "    def __init__(self, x: int | float, y: int | float,\n",
        "                 w: int | float, h: int | float,\n",
        "                 spd: int | float = 1):\n",
        "        self.x, self.y = x, y\n",
        "        self.w, self.h = w, h\n",
        "        self.left, self.right = self.x - self.w / 2, self.x + self.w / 2\n",
        "        self.top, self.bottom = self.x - self.h / 2, self.x + self.h / 2\n",
        "        self.spd = spd\n",
        "        self.score = 0\n",
        "\n",
        "\n",
        "class PongEnv(gym.Env):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.width, self.height = 900, 600\n",
        "        self.ball_speed = 6\n",
        "        self.paddle_speed = 6\n",
        "        self.ball = Ball(self.width / 2, self.height / 2,\n",
        "                         random.choice([1, -1]) * self.ball_speed, random.choice([1, -1]) * self.ball_speed)\n",
        "        self.player = Paddle(self.width - 100, self.height / 2, 10, 100)\n",
        "        self.opponent = Paddle(100, self.height / 2, 10, 100)\n",
        "        self.frame = 0\n",
        "        self.action_space = gym.spaces.Discrete(3)\n",
        "        self.observation_space = gym.spaces.Box(-10000000.0, 10000000.0, shape=(8,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.ball = Ball(self.width / 2, self.height / 2,\n",
        "                         random.choice([1, -1]) * self.ball_speed, random.choice([1, -1]) * self.ball_speed)\n",
        "        self.player = Paddle(self.width - 100, self.height / 2, 10, 100)\n",
        "        self.opponent = Paddle(100, self.height / 2, 10, 100)\n",
        "        self.frame = 0\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        return observation, info\n",
        "\n",
        "    def step(self, action):\n",
        "        reward = 0\n",
        "\n",
        "        if action == 1:\n",
        "            self.player.y = max(0, self.player.y - self.player.spd)\n",
        "        elif action == 2:\n",
        "            self.player.y = min(self.height, self.player.y + self.player.spd)\n",
        "\n",
        "        if self.ball.y >= self.height:\n",
        "            self.ball.spdy = -self.ball_speed\n",
        "        elif self.ball.y <= 0:\n",
        "            self.ball.spdy *= self.ball_speed\n",
        "\n",
        "        if self.ball.x <= 0:\n",
        "            reward = 100\n",
        "            self.ball = Ball(self.width / 2, self.height / 2,\n",
        "                             random.choice([1, -1]) * self.ball_speed, random.choice([1, -1]) * self.ball_speed)\n",
        "            self.player.score += 1\n",
        "        elif self.ball.x >= self.width:\n",
        "            reward = -100\n",
        "            self.ball = Ball(self.width / 2, self.height / 2,\n",
        "                             random.choice([1, -1]) * self.ball_speed, random.choice([1, -1]) * self.ball_speed)\n",
        "            self.opponent.score += 1\n",
        "\n",
        "        if self.player.x - self.ball.r <= self.ball.x <= self.player.right \\\n",
        "                and self.player.top - self.ball.r <= self.ball.y <= self.player.bottom + self.ball.r:\n",
        "            self.ball.spdx = -self.ball_speed\n",
        "            reward = 1\n",
        "        if self.opponent.x - self.ball.r <= self.ball.x <= self.opponent.right \\\n",
        "                and self.opponent.top - self.ball.r <= self.ball.y <= self.opponent.bottom + self.ball.r:\n",
        "            self.ball.spdx = self.ball_speed\n",
        "\n",
        "        if self.frame % 8:\n",
        "            if self.opponent.y < self.ball.y:\n",
        "                self.opponent.top += self.paddle_speed\n",
        "            else:\n",
        "                self.opponent.bottom -= self.paddle_speed\n",
        "\n",
        "        self.ball.x += self.ball.spdx\n",
        "        self.ball.y += self.ball.spdy\n",
        "\n",
        "        self.frame += 1\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        return observation, reward, False, False, info\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return np.array([\n",
        "            self.ball.x, self.ball.y, self.ball.spdx, self.ball.spdy,\n",
        "            self.player.x, self.player.y, self.opponent.x, self.opponent.y\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def _get_info(self):\n",
        "        \"\"\"Compute auxiliary information for debugging.\n",
        "\n",
        "        Returns:\n",
        "            dict: Info with distance between agent and target\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'Player score': self.player.score,\n",
        "            'Opponent score': self.opponent.score\n",
        "        }\n",
        "\n",
        "gym.register(\n",
        "    id=\"Pong_custom\",\n",
        "    entry_point=PongEnv,\n",
        "    max_episode_steps=1200,  # Prevent infinite episodes\n",
        ")"
      ],
      "id": "initial_id",
      "outputs": [],
      "execution_count": 22
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-29T13:58:26.894539Z",
          "start_time": "2025-07-29T13:58:26.885437Z"
        },
        "id": "4fac622abcb9abbe"
      },
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, action_dim, lr, gamma, epsilon, epsilon_decay, buffer_size):\n",
        "        self.action_dim = action_dim\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_dim)\n",
        "        q_values = model(torch.tensor(state, dtype=torch.float32).to(device))\n",
        "        return torch.argmax(q_values).item()\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        if len(self.memory) < batch_size:\n",
        "            return\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).to(device)\n",
        "            next_state_tensor = torch.tensor(next_state, dtype=torch.float32).to(device)\n",
        "            if not done:\n",
        "                logits = model(next_state_tensor)\n",
        "                target = reward + self.gamma * torch.max(logits).item()\n",
        "\n",
        "            target_f = model(state_tensor)\n",
        "            target_f[action] = target\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = nn.MSELoss()(target_f, model(state_tensor))\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        if self.epsilon > 0.01:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "id": "4fac622abcb9abbe",
      "outputs": [],
      "execution_count": 23
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-29T13:58:27.323267Z",
          "start_time": "2025-07-29T13:58:27.315264Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206b6160fa4e5b87",
        "outputId": "64a60fd8-811a-42aa-b19d-d9c98ac2e84b"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = DQN().to(device)\n",
        "\n",
        "device"
      ],
      "id": "206b6160fa4e5b87",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": 24
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-29T13:58:47.464864Z",
          "start_time": "2025-07-29T13:58:27.732863Z"
        },
        "id": "5fb12e08f616c769"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('Pong_custom')\n",
        "action_dim = 3\n",
        "agent = DQNAgent(action_dim, lr=0.01, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, buffer_size=10000)\n",
        "\n",
        "batch_size = 32\n",
        "num_episodes = 10\n",
        "for episode in range(num_episodes):\n",
        "    state, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    frames = 0\n",
        "    while not done and frames <= 1200:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        agent.replay(batch_size)\n",
        "        frames += 1\n",
        "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}\")"
      ],
      "id": "5fb12e08f616c769",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "998246538a36256c"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "998246538a36256c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}